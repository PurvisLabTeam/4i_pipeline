{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates a set of transformations based on segmented masks.\n",
    "\n",
    "Input:\n",
    "- pathway to a directory containing segmented labels\n",
    "- pathway to a directory containing data frames\n",
    "- list of wells to process\n",
    "- downscale factor (1 - no downscaling, 2 - will make images 4 times smaller)\n",
    "\n",
    "Output:\n",
    "- a set of transforms for each well saved as pkl files\n",
    "\n",
    "Downscale factor allows for calculations of transformations on smaller images (for huge images StackReg may run out of RAM - downscaling prevents solves the issue).\n",
    "\n",
    "Optionally you can visualize alignment on downscaled images (visualization uses Napari)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in info about the experiment to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathway to a directory with segmented masks for alignment (ex. im_segmented)\n",
    "path_labels = r'C:\\Users\\gases\\Desktop\\DataForAyra\\segmented'\n",
    "\n",
    "# pathway to a directory with data frames (ex. df)\n",
    "path_df = r'C:\\Users\\gases\\Desktop\\DataForAyra\\output_df'\n",
    "\n",
    "# list of wells to be processed (usually names as 'A3')\n",
    "\n",
    "well_list = ['A1']\n",
    "\n",
    "#well_list = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09',\n",
    "#            'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08', 'C09',\n",
    "#            'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09',\n",
    "#            'E02', 'E03', 'E04', 'E05', 'E06', 'E07', 'E08', 'E09']\n",
    "# pathway to save transformations (ex. df)\n",
    "path_save = r'C:\\Users\\gases\\Desktop\\DataForAyra\\output_df'\n",
    "\n",
    "# specify a downscaling factor for the alignment\n",
    "downscale_factor = 1 \n",
    "\n",
    "# specify anchor round (to which alignment will be done)\n",
    "anchor_round_selected = 1 # as named in the directory, default should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.transform import downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pystackreg import StackReg\n",
    "import pystackreg\n",
    "\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path_labels,myWell):\n",
    "    \n",
    "    labels_list = [x for x in os.listdir(os.path.join(path_labels,myWell)) if 'tif' in x]\n",
    "    labels_list.sort()\n",
    "\n",
    "    labels_im_list = []\n",
    "    for lab_im_name in labels_list:\n",
    "\n",
    "        lab_im = plt.imread(os.path.join(path_labels,myWell,lab_im_name))\n",
    "        labels_im_list.append(lab_im)\n",
    "\n",
    "    labels_im = np.array(labels_im_list)\n",
    "    \n",
    "    return labels_im\n",
    "\n",
    "def rescale_transforms(tmat_org,downscale_factor):\n",
    "     \n",
    "    # rescale transformation\n",
    "    if downscale_factor != 1:\n",
    "        \n",
    "        tmat = []\n",
    "\n",
    "        for tranform_matrix in tmat_org:\n",
    "\n",
    "            eu_transform_small = transform.EuclideanTransform(tranform_matrix)\n",
    "\n",
    "            eu_transform = transform.EuclideanTransform(translation = eu_transform_small.translation * downscale_factor,\n",
    "                                                        rotation = eu_transform_small.rotation)\n",
    "\n",
    "            tmat.append(eu_transform)\n",
    "            \n",
    "    else:\n",
    "        tmat = tmat_org\n",
    "            \n",
    "    return tmat\n",
    "\n",
    "def find_transformation(labels_im,anchor_round,downscale_factor = 1):\n",
    "\n",
    "    # resize the image\n",
    "    labels_small = labels_im>0\n",
    "    labels_small = downscale_local_mean(labels_small,(1,downscale_factor,downscale_factor))\n",
    "\n",
    "    \n",
    "    # find transformation\n",
    "    tf = StackReg.RIGID_BODY\n",
    "    sr = StackReg(tf)\n",
    "    \n",
    "    tmat_small = []\n",
    "    for frame in range(labels_small.shape[0]):\n",
    "\n",
    "        print(frame)\n",
    "        \n",
    "        if frame==anchor_round:\n",
    "            tmat_frame = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "        else:\n",
    "            tmat_frame = sr.register(labels_small[anchor_round],labels_small[frame])\n",
    "\n",
    "        tmat_small.append(tmat_frame)\n",
    "\n",
    "    tmat_small = np.asarray(tmat_small)\n",
    "\n",
    "    # rescale transformation\n",
    "    tmat = rescale_transforms(tmat_small,downscale_factor)\n",
    "            \n",
    "    return tmat,tmat_small\n",
    "\n",
    "def apply_transforms_set(tmat,movie):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for index,tranform_matrix in enumerate(tmat):\n",
    "    \n",
    "        eu_transform = transform.EuclideanTransform(tranform_matrix)\n",
    "\n",
    "        # if you want to check only transformation without rotation\n",
    "        #eu_transform_small = transform.EuclideanTransform(translation = eu_transform_small.translation, rotation = 0)\n",
    "\n",
    "        temp = transform.warp(movie[index,:,:],eu_transform,output_shape=movie[index].shape)\n",
    "\n",
    "        res.append(temp)\n",
    "\n",
    "    res = np.array(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing well A1.\n",
      "Number of label images 3\n",
      "Number of unique rounds 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`block_size` must be a scalar or have the same length as `image.shape`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7508\\3708121790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# find transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtmat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmat_small\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_im\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manchor_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownscale_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownscale_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# save transformations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7508\\3983467133.py\u001b[0m in \u001b[0;36mfind_transformation\u001b[1;34m(labels_im, anchor_round, downscale_factor)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# resize the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mlabels_small\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_im\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mlabels_small\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownscale_local_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_small\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownscale_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownscale_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gases\\.conda\\envs\\GPU_Segment_4i\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mdownscale_local_mean\u001b[1;34m(image, factors, cval, clip)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \"\"\"\n\u001b[1;32m--> 505\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mblock_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gases\\.conda\\envs\\GPU_Segment_4i\\lib\\site-packages\\skimage\\measure\\block.py\u001b[0m in \u001b[0;36mblock_reduce\u001b[1;34m(image, block_size, func, cval, func_kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mblock_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         raise ValueError(\"`block_size` must be a scalar or have \"\n\u001b[0m\u001b[0;32m     67\u001b[0m                          \"the same length as `image.shape`\")\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `block_size` must be a scalar or have the same length as `image.shape`"
     ]
    }
   ],
   "source": [
    "for myWell in well_list:\n",
    "    \n",
    "    print(f'Processing well {myWell}.')\n",
    "    \n",
    "    # read in the data\n",
    "    myData = pd.read_pickle(os.path.join(path_df,f'df_{myWell}.pkl'))\n",
    "    \n",
    "    # read in all the labels\n",
    "    labels_im = read_labels(path_labels,myWell)\n",
    "    \n",
    "    # check if you have an expected number of files to align\n",
    "    print(f'Number of label images {labels_im.shape[0]}')\n",
    "    print(f'Number of unique rounds {len(set(myData.alignRound))}')\n",
    "    \n",
    "    # check which alignRound for the anchor round\n",
    "    #anchor_round = myData.loc[myData.nameRound == anchor_round_selected,'alignRound'].tolist()[0]\n",
    "    #anchor_round = int(anchor_round)\n",
    "    #Had to manually set the anchor round here, since the modified info_csv wasn't parsed by the existing structure\n",
    "    anchor_round = 0\n",
    "    \n",
    "    # find transformation\n",
    "    tmat,tmat_small = find_transformation(labels_im,anchor_round,downscale_factor = downscale_factor)\n",
    "    \n",
    "    # save transformations\n",
    "    save_file_path = os.path.join(path_save,f'tmat_{myWell}.pkl')\n",
    "    pickle.dump(tmat, open(save_file_path, \"wb\"))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'labels_small_aligned' at 0x2788339f730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test transformations\n",
    "\n",
    "# choose on which well to perform tests \n",
    "myWell = 'C03'\n",
    "\n",
    "# read in images\n",
    "labels_im = read_labels(path_labels,myWell)\n",
    "\n",
    "# read in transformation matrix\n",
    "tmat_list = pickle.load(open(os.path.join(path_save,f'tmat_{myWell}.pkl'), \"rb\"))\n",
    "tmat_small = rescale_transforms(tmat_list,1/downscale_factor)\n",
    "\n",
    "labels_small = downscale_local_mean(labels_im,(1,downscale_factor,downscale_factor))\n",
    "labels_small_aligned = apply_transforms_set(tmat_small,labels_small)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(labels_small[anchor_round],blending ='additive',colormap='gray')\n",
    "viewer.add_image(labels_small,blending ='additive',colormap='red')\n",
    "viewer.add_image(labels_small_aligned,blending ='additive',colormap='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
